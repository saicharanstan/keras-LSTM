{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import nan\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import LSTM, Dense\n",
    "from tensorflow.python.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datasets importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LT</th>\n",
       "      <th>TEC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.311333</td>\n",
       "      <td>2.067562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.344670</td>\n",
       "      <td>2.082707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.378006</td>\n",
       "      <td>2.004272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.411343</td>\n",
       "      <td>1.736569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.444679</td>\n",
       "      <td>1.758503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LT       TEC\n",
       "0  5.311333  2.067562\n",
       "1  5.344670  2.082707\n",
       "2  5.378006  2.004272\n",
       "3  5.411343  1.736569\n",
       "4  5.444679  1.758503"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('Train_TEC_mar17.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LT</th>\n",
       "      <th>TEC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.311570</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.344906</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.378243</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.411580</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.444917</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LT  TEC\n",
       "0  5.311570  NaN\n",
       "1  5.344906  NaN\n",
       "2  5.378243  NaN\n",
       "3  5.411580  NaN\n",
       "4  5.444917  NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('Test_TEC_mar17.csv')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preparing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13680,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = df1[\"LT\"][:-720]\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13680,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = df1[\"TEC\"][:-720]\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (-1, X_train.shape[0], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14400 samples\n",
      "Epoch 1/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 18.5899\n",
      "Epoch 2/100\n",
      "14400/14400 [==============================] - 1s 99us/sample - loss: 18.5760\n",
      "Epoch 3/100\n",
      "14400/14400 [==============================] - 1s 99us/sample - loss: 18.2985\n",
      "Epoch 4/100\n",
      "14400/14400 [==============================] - 1s 102us/sample - loss: 18.4556\n",
      "Epoch 5/100\n",
      "14400/14400 [==============================] - 1s 100us/sample - loss: 18.9152\n",
      "Epoch 6/100\n",
      "14400/14400 [==============================] - 1s 97us/sample - loss: 17.9397\n",
      "Epoch 7/100\n",
      "14400/14400 [==============================] - 1s 101us/sample - loss: 18.6007\n",
      "Epoch 8/100\n",
      "14400/14400 [==============================] - 2s 106us/sample - loss: 18.0604\n",
      "Epoch 9/100\n",
      "14400/14400 [==============================] - 1s 97us/sample - loss: 18.5328\n",
      "Epoch 10/100\n",
      "14400/14400 [==============================] - 1s 97us/sample - loss: 18.2255\n",
      "Epoch 11/100\n",
      "14400/14400 [==============================] - 1s 97us/sample - loss: 18.4708\n",
      "Epoch 12/100\n",
      "14400/14400 [==============================] - 1s 96us/sample - loss: 18.3637\n",
      "Epoch 13/100\n",
      "14400/14400 [==============================] - 1s 97us/sample - loss: 18.1809\n",
      "Epoch 14/100\n",
      "14400/14400 [==============================] - 1s 97us/sample - loss: 18.0540\n",
      "Epoch 15/100\n",
      "14400/14400 [==============================] - 1s 96us/sample - loss: 17.4016\n",
      "Epoch 16/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 17.0225\n",
      "Epoch 17/100\n",
      "14400/14400 [==============================] - 1s 104us/sample - loss: 15.9725\n",
      "Epoch 18/100\n",
      "14400/14400 [==============================] - 1s 97us/sample - loss: 15.1827\n",
      "Epoch 19/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 14.7018\n",
      "Epoch 20/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 13.7040\n",
      "Epoch 21/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 13.4475\n",
      "Epoch 22/100\n",
      "14400/14400 [==============================] - 1s 97us/sample - loss: 13.1080\n",
      "Epoch 23/100\n",
      "14400/14400 [==============================] - 1s 97us/sample - loss: 12.7430\n",
      "Epoch 24/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 12.4417\n",
      "Epoch 25/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 12.5662\n",
      "Epoch 26/100\n",
      "14400/14400 [==============================] - 1s 104us/sample - loss: 12.0843\n",
      "Epoch 27/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 11.9660\n",
      "Epoch 28/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 12.0726\n",
      "Epoch 29/100\n",
      "14400/14400 [==============================] - 1s 97us/sample - loss: 11.7844\n",
      "Epoch 30/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 11.7210\n",
      "Epoch 31/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 11.5627\n",
      "Epoch 32/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 11.4384\n",
      "Epoch 33/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 11.3873\n",
      "Epoch 34/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 11.3625\n",
      "Epoch 35/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 11.2225\n",
      "Epoch 36/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 11.1990\n",
      "Epoch 37/100\n",
      "14400/14400 [==============================] - 1s 99us/sample - loss: 11.1218\n",
      "Epoch 38/100\n",
      "14400/14400 [==============================] - 1s 104us/sample - loss: 11.0929\n",
      "Epoch 39/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 11.0244\n",
      "Epoch 40/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 10.9145\n",
      "Epoch 41/100\n",
      "14400/14400 [==============================] - 2s 106us/sample - loss: 11.1503\n",
      "Epoch 42/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 10.8180\n",
      "Epoch 43/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 11.1010\n",
      "Epoch 44/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 11.0860\n",
      "Epoch 45/100\n",
      "14400/14400 [==============================] - 1s 98us/sample - loss: 10.8865\n",
      "Epoch 46/100\n",
      "14400/14400 [==============================] - 1s 99us/sample - loss: 10.8496\n",
      "Epoch 47/100\n",
      "14400/14400 [==============================] - 1s 101us/sample - loss: 10.8314\n",
      "Epoch 48/100\n",
      "14400/14400 [==============================] - 2s 107us/sample - loss: 10.7659\n",
      "Epoch 49/100\n",
      "14400/14400 [==============================] - 2s 108us/sample - loss: 10.5849\n",
      "Epoch 50/100\n",
      "14400/14400 [==============================] - 2s 127us/sample - loss: 10.6989\n",
      "Epoch 51/100\n",
      "14400/14400 [==============================] - 1s 103us/sample - loss: 10.8705\n",
      "Epoch 52/100\n",
      "14400/14400 [==============================] - 2s 105us/sample - loss: 10.5044\n",
      "Epoch 53/100\n",
      "14400/14400 [==============================] - 1s 104us/sample - loss: 10.4807\n",
      "Epoch 54/100\n",
      "14400/14400 [==============================] - 1s 104us/sample - loss: 10.4281\n",
      "Epoch 55/100\n",
      "14400/14400 [==============================] - 1s 103us/sample - loss: 10.6068\n",
      "Epoch 56/100\n",
      "14400/14400 [==============================] - 1s 103us/sample - loss: 10.6715\n",
      "Epoch 57/100\n",
      "14400/14400 [==============================] - 1s 103us/sample - loss: 10.6034\n",
      "Epoch 58/100\n",
      "14400/14400 [==============================] - 1s 104us/sample - loss: 10.4837\n",
      "Epoch 59/100\n",
      "14400/14400 [==============================] - 2s 108us/sample - loss: 10.4669\n",
      "Epoch 60/100\n",
      "14400/14400 [==============================] - 2s 107us/sample - loss: 10.4031\n",
      "Epoch 61/100\n",
      "14400/14400 [==============================] - 2s 113us/sample - loss: 10.6541\n",
      "Epoch 62/100\n",
      "14400/14400 [==============================] - 2s 126us/sample - loss: 10.6415\n",
      "Epoch 63/100\n",
      "14400/14400 [==============================] - 2s 109us/sample - loss: 10.3624\n",
      "Epoch 64/100\n",
      "14400/14400 [==============================] - 2s 105us/sample - loss: 10.2270\n",
      "Epoch 65/100\n",
      "14400/14400 [==============================] - 2s 105us/sample - loss: 10.5129\n",
      "Epoch 66/100\n",
      "14400/14400 [==============================] - 1s 104us/sample - loss: 10.3473\n",
      "Epoch 67/100\n",
      "14400/14400 [==============================] - 1s 102us/sample - loss: 10.3331\n",
      "Epoch 68/100\n",
      "14400/14400 [==============================] - 1s 104us/sample - loss: 10.3345\n",
      "Epoch 69/100\n",
      "14400/14400 [==============================] - 1s 104us/sample - loss: 10.0800\n",
      "Epoch 70/100\n",
      "14400/14400 [==============================] - 2s 105us/sample - loss: 10.1824\n",
      "Epoch 71/100\n",
      "14400/14400 [==============================] - 1s 104us/sample - loss: 10.1439\n",
      "Epoch 72/100\n",
      "14400/14400 [==============================] - 2s 104us/sample - loss: 10.2589\n",
      "Epoch 73/100\n",
      "14400/14400 [==============================] - 1s 104us/sample - loss: 10.3626\n",
      "Epoch 74/100\n",
      "14400/14400 [==============================] - 2s 105us/sample - loss: 10.1519\n",
      "Epoch 75/100\n",
      "14400/14400 [==============================] - 2s 105us/sample - loss: 10.0977\n",
      "Epoch 76/100\n",
      "14400/14400 [==============================] - 1s 104us/sample - loss: 10.1715\n",
      "Epoch 77/100\n",
      "14400/14400 [==============================] - 2s 104us/sample - loss: 10.1601\n",
      "Epoch 78/100\n",
      "14400/14400 [==============================] - 2s 107us/sample - loss: 10.1127\n",
      "Epoch 79/100\n",
      "14400/14400 [==============================] - 2s 105us/sample - loss: 10.1595\n",
      "Epoch 80/100\n",
      "14400/14400 [==============================] - 1s 104us/sample - loss: 9.9316\n",
      "Epoch 81/100\n",
      "14400/14400 [==============================] - 1s 104us/sample - loss: 10.2463\n",
      "Epoch 82/100\n",
      "14400/14400 [==============================] - 1s 104us/sample - loss: 10.0420\n",
      "Epoch 83/100\n",
      "14400/14400 [==============================] - 1s 104us/sample - loss: 10.1608\n",
      "Epoch 84/100\n",
      "14400/14400 [==============================] - 2s 104us/sample - loss: 10.0969\n",
      "Epoch 85/100\n",
      "14400/14400 [==============================] - 1s 104us/sample - loss: 9.9631\n",
      "Epoch 86/100\n",
      "14400/14400 [==============================] - 2s 104us/sample - loss: 9.9839\n",
      "Epoch 87/100\n",
      "14400/14400 [==============================] - 1s 104us/sample - loss: 10.0968\n",
      "Epoch 88/100\n",
      "14400/14400 [==============================] - 2s 104us/sample - loss: 10.1286\n",
      "Epoch 89/100\n",
      "14400/14400 [==============================] - 1s 104us/sample - loss: 10.0363\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14400/14400 [==============================] - 1s 99us/sample - loss: 10.0360\n",
      "Epoch 91/100\n",
      "14400/14400 [==============================] - 1s 102us/sample - loss: 10.0981\n",
      "Epoch 92/100\n",
      "14400/14400 [==============================] - 1s 101us/sample - loss: 9.8730\n",
      "Epoch 93/100\n",
      "14400/14400 [==============================] - 2s 114us/sample - loss: 9.7922\n",
      "Epoch 94/100\n",
      "14400/14400 [==============================] - 1s 102us/sample - loss: 9.9800\n",
      "Epoch 95/100\n",
      "14400/14400 [==============================] - 1s 101us/sample - loss: 9.7920\n",
      "Epoch 96/100\n",
      "14400/14400 [==============================] - 1s 101us/sample - loss: 9.8773\n",
      "Epoch 97/100\n",
      "14400/14400 [==============================] - 1s 101us/sample - loss: 9.8186\n",
      "Epoch 98/100\n",
      "14400/14400 [==============================] - 1s 103us/sample - loss: 9.9461\n",
      "Epoch 99/100\n",
      "14400/14400 [==============================] - 2s 104us/sample - loss: 9.7452\n",
      "Epoch 100/100\n",
      "14400/14400 [==============================] - 2s 105us/sample - loss: 9.8495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x256271f7688>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, Y_train, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df2[\"LT\"][-720:].values\n",
    "# x_test.shape\n",
    "X_test = x_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = np.reshape(X_test, (-1, 720, 1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.31174912],\n",
       "       [ 5.34508639],\n",
       "       [ 5.37842365],\n",
       "       [ 5.41176098],\n",
       "       [ 5.44509833],\n",
       "       [ 5.4784357 ],\n",
       "       [ 5.51177311],\n",
       "       [ 5.54511054],\n",
       "       [ 5.578448  ],\n",
       "       [ 5.61178546],\n",
       "       [ 5.64512299],\n",
       "       [ 5.67846052],\n",
       "       [ 5.71179812],\n",
       "       [ 5.74513572],\n",
       "       [ 5.77847334],\n",
       "       [ 5.81181099],\n",
       "       [ 5.84514872],\n",
       "       [ 5.8784864 ],\n",
       "       [ 5.91182419],\n",
       "       [ 5.94516195],\n",
       "       [ 5.97849981],\n",
       "       [ 6.01183763],\n",
       "       [ 6.04517553],\n",
       "       [ 6.07851342],\n",
       "       [ 6.11185137],\n",
       "       [ 6.14518933],\n",
       "       [ 6.17852735],\n",
       "       [ 6.21186536],\n",
       "       [ 6.24520344],\n",
       "       [ 6.27854154],\n",
       "       [ 6.31187967],\n",
       "       [ 6.34521781],\n",
       "       [ 6.37855598],\n",
       "       [ 6.41189421],\n",
       "       [ 6.44523246],\n",
       "       [ 6.47857072],\n",
       "       [ 6.51190902],\n",
       "       [ 6.54524737],\n",
       "       [ 6.57858573],\n",
       "       [ 6.61192413],\n",
       "       [ 6.64526251],\n",
       "       [ 6.678601  ],\n",
       "       [ 6.71193948],\n",
       "       [ 6.74527796],\n",
       "       [ 6.77861651],\n",
       "       [ 6.81195508],\n",
       "       [ 6.84529367],\n",
       "       [ 6.87863226],\n",
       "       [ 6.91197094],\n",
       "       [ 6.94530957],\n",
       "       [ 6.97864828],\n",
       "       [ 7.01198704],\n",
       "       [ 7.04532578],\n",
       "       [ 7.07866457],\n",
       "       [ 7.11200331],\n",
       "       [ 7.14534218],\n",
       "       [ 7.178681  ],\n",
       "       [ 7.21201985],\n",
       "       [ 7.24535878],\n",
       "       [ 7.27869766],\n",
       "       [ 7.31203662],\n",
       "       [ 7.34537554],\n",
       "       [ 7.37871457],\n",
       "       [ 7.41205353],\n",
       "       [ 7.44539257],\n",
       "       [ 7.47873157],\n",
       "       [ 7.51207064],\n",
       "       [ 7.5454097 ],\n",
       "       [ 7.57874877],\n",
       "       [ 7.61208789],\n",
       "       [ 7.64542701],\n",
       "       [ 7.67876614],\n",
       "       [ 7.71210528],\n",
       "       [ 7.74544443],\n",
       "       [ 7.7787836 ],\n",
       "       [ 7.8121228 ],\n",
       "       [ 7.84546199],\n",
       "       [ 7.8788012 ],\n",
       "       [ 7.91214043],\n",
       "       [ 7.94547965],\n",
       "       [ 7.97881887],\n",
       "       [ 8.01215811],\n",
       "       [ 8.04549736],\n",
       "       [ 8.07883661],\n",
       "       [ 8.11217588],\n",
       "       [ 8.14551515],\n",
       "       [ 8.1788544 ],\n",
       "       [ 8.21219366],\n",
       "       [ 8.24553293],\n",
       "       [ 8.27887223],\n",
       "       [ 8.31221149],\n",
       "       [ 8.34555079],\n",
       "       [ 8.37889002],\n",
       "       [ 8.41222929],\n",
       "       [ 8.44556854],\n",
       "       [ 8.47890779],\n",
       "       [ 8.51224704],\n",
       "       [ 8.54558629],\n",
       "       [ 8.57892552],\n",
       "       [ 8.61226476],\n",
       "       [ 8.64560397],\n",
       "       [ 8.67894317],\n",
       "       [ 8.71228236],\n",
       "       [ 8.74562152],\n",
       "       [ 8.7789607 ],\n",
       "       [ 8.81229989],\n",
       "       [ 8.84563899],\n",
       "       [ 8.87897811],\n",
       "       [ 8.91231724],\n",
       "       [ 8.94565632],\n",
       "       [ 8.9789954 ],\n",
       "       [ 9.01233444],\n",
       "       [ 9.04567346],\n",
       "       [ 9.07901244],\n",
       "       [ 9.1123514 ],\n",
       "       [ 9.14569036],\n",
       "       [ 9.1790293 ],\n",
       "       [ 9.21236816],\n",
       "       [ 9.24570704],\n",
       "       [ 9.27904587],\n",
       "       [ 9.31238469],\n",
       "       [ 9.34572345],\n",
       "       [ 9.3790622 ],\n",
       "       [ 9.41240089],\n",
       "       [ 9.44573953],\n",
       "       [ 9.47907817],\n",
       "       [ 9.5124168 ],\n",
       "       [ 9.54575534],\n",
       "       [ 9.57909383],\n",
       "       [ 9.61243231],\n",
       "       [ 9.64577071],\n",
       "       [ 9.67910911],\n",
       "       [ 9.71244748],\n",
       "       [ 9.7457858 ],\n",
       "       [ 9.77912401],\n",
       "       [ 9.81246222],\n",
       "       [ 9.84580039],\n",
       "       [ 9.87913847],\n",
       "       [ 9.91247653],\n",
       "       [ 9.94581453],\n",
       "       [ 9.97915252],\n",
       "       [10.01249037],\n",
       "       [10.04582823],\n",
       "       [10.07916604],\n",
       "       [10.11250375],\n",
       "       [10.14584142],\n",
       "       [10.17917903],\n",
       "       [10.21251654],\n",
       "       [10.24585406],\n",
       "       [10.27919148],\n",
       "       [10.31252885],\n",
       "       [10.34586613],\n",
       "       [10.37920337],\n",
       "       [10.41254054],\n",
       "       [10.44587757],\n",
       "       [10.47921461],\n",
       "       [10.51255161],\n",
       "       [10.54588846],\n",
       "       [10.57922526],\n",
       "       [10.612562  ],\n",
       "       [10.64589866],\n",
       "       [10.67923525],\n",
       "       [10.71257181],\n",
       "       [10.74590825],\n",
       "       [10.77924456],\n",
       "       [10.81258087],\n",
       "       [10.84591708],\n",
       "       [10.87925319],\n",
       "       [10.91258922],\n",
       "       [10.94592516],\n",
       "       [10.97926101],\n",
       "       [11.0125968 ],\n",
       "       [11.04593253],\n",
       "       [11.07926814],\n",
       "       [11.11260365],\n",
       "       [11.14593913],\n",
       "       [11.17927449],\n",
       "       [11.21260976],\n",
       "       [11.2459449 ],\n",
       "       [11.27927999],\n",
       "       [11.31261503],\n",
       "       [11.34594994],\n",
       "       [11.37928476],\n",
       "       [11.41261948],\n",
       "       [11.44595407],\n",
       "       [11.47928862],\n",
       "       [11.51262306],\n",
       "       [11.54595743],\n",
       "       [11.57929165],\n",
       "       [11.61262584],\n",
       "       [11.64595989],\n",
       "       [11.67929387],\n",
       "       [11.7126277 ],\n",
       "       [11.74596147],\n",
       "       [11.77929513],\n",
       "       [11.8126287 ],\n",
       "       [11.84596217],\n",
       "       [11.87929556],\n",
       "       [11.91262881],\n",
       "       [11.94596191],\n",
       "       [11.97929499],\n",
       "       [12.01262793],\n",
       "       [12.0459608 ],\n",
       "       [12.07929354],\n",
       "       [12.11262617],\n",
       "       [12.14595872],\n",
       "       [12.17929119],\n",
       "       [12.21262352],\n",
       "       [12.24595575],\n",
       "       [12.27928788],\n",
       "       [12.3126199 ],\n",
       "       [12.3459518 ],\n",
       "       [12.37928362],\n",
       "       [12.41261533],\n",
       "       [12.4459469 ],\n",
       "       [12.4792784 ],\n",
       "       [12.51260979],\n",
       "       [12.54594107],\n",
       "       [12.57927225],\n",
       "       [12.61260331],\n",
       "       [12.64593431],\n",
       "       [12.67926517],\n",
       "       [12.7125959 ],\n",
       "       [12.74592654],\n",
       "       [12.77925707],\n",
       "       [12.81258751],\n",
       "       [12.84591785],\n",
       "       [12.87924805],\n",
       "       [12.91257818],\n",
       "       [12.94590816],\n",
       "       [12.97923809],\n",
       "       [13.01256793],\n",
       "       [13.04589761],\n",
       "       [13.0792272 ],\n",
       "       [13.11255669],\n",
       "       [13.1458861 ],\n",
       "       [13.17921536],\n",
       "       [13.21254453],\n",
       "       [13.24587363],\n",
       "       [13.2792026 ],\n",
       "       [13.31253147],\n",
       "       [13.34586026],\n",
       "       [13.37918894],\n",
       "       [13.41251752],\n",
       "       [13.445846  ],\n",
       "       [13.47917439],\n",
       "       [13.51250266],\n",
       "       [13.54583085],\n",
       "       [13.57915891],\n",
       "       [13.61248693],\n",
       "       [13.6458148 ],\n",
       "       [13.6791426 ],\n",
       "       [13.71247028],\n",
       "       [13.7457979 ],\n",
       "       [13.77912542],\n",
       "       [13.81245282],\n",
       "       [13.84578016],\n",
       "       [13.87910738],\n",
       "       [13.91243451],\n",
       "       [13.94576158],\n",
       "       [13.97908855],\n",
       "       [14.01241542],\n",
       "       [14.04574221],\n",
       "       [14.07906892],\n",
       "       [14.11239553],\n",
       "       [14.14572205],\n",
       "       [14.17904852],\n",
       "       [14.21237487],\n",
       "       [14.24570114],\n",
       "       [14.27902733],\n",
       "       [14.31235346],\n",
       "       [14.34567951],\n",
       "       [14.37900547],\n",
       "       [14.41233135],\n",
       "       [14.44565716],\n",
       "       [14.47898288],\n",
       "       [14.51230854],\n",
       "       [14.54563415],\n",
       "       [14.57895966],\n",
       "       [14.6122851 ],\n",
       "       [14.64561046],\n",
       "       [14.67893579],\n",
       "       [14.71226101],\n",
       "       [14.74558618],\n",
       "       [14.77891127],\n",
       "       [14.81223632],\n",
       "       [14.84556131],\n",
       "       [14.87888622],\n",
       "       [14.91221107],\n",
       "       [14.94553586],\n",
       "       [14.97886061],\n",
       "       [15.01218529],\n",
       "       [15.0455099 ],\n",
       "       [15.07883448],\n",
       "       [15.112159  ],\n",
       "       [15.14548346],\n",
       "       [15.17880792],\n",
       "       [15.21213225],\n",
       "       [15.24545659],\n",
       "       [15.27878087],\n",
       "       [15.31210511],\n",
       "       [15.3454293 ],\n",
       "       [15.37875344],\n",
       "       [15.41207753],\n",
       "       [15.4454016 ],\n",
       "       [15.47872558],\n",
       "       [15.51204959],\n",
       "       [15.54537354],\n",
       "       [15.57869744],\n",
       "       [15.61202136],\n",
       "       [15.64534519],\n",
       "       [15.67866902],\n",
       "       [15.71199285],\n",
       "       [15.74531662],\n",
       "       [15.77864039],\n",
       "       [15.81196413],\n",
       "       [15.84528785],\n",
       "       [15.87861152],\n",
       "       [15.91193517],\n",
       "       [15.94525879],\n",
       "       [15.97858245],\n",
       "       [16.01190606],\n",
       "       [16.04522965],\n",
       "       [16.07855322],\n",
       "       [16.11187684],\n",
       "       [16.14520041],\n",
       "       [16.178524  ],\n",
       "       [16.21184751],\n",
       "       [16.2451711 ],\n",
       "       [16.27849465],\n",
       "       [16.3118182 ],\n",
       "       [16.34514175],\n",
       "       [16.37846529],\n",
       "       [16.41178881],\n",
       "       [16.44511242],\n",
       "       [16.47843596],\n",
       "       [16.51175953],\n",
       "       [16.54508311],\n",
       "       [16.57840668],\n",
       "       [16.6117303 ],\n",
       "       [16.64505392],\n",
       "       [16.67837755],\n",
       "       [16.71170123],\n",
       "       [16.74502484],\n",
       "       [16.77834853],\n",
       "       [16.81167225],\n",
       "       [16.84499596],\n",
       "       [16.87831972],\n",
       "       [16.91164349],\n",
       "       [16.9449673 ],\n",
       "       [16.9782911 ],\n",
       "       [17.01161494],\n",
       "       [17.04493882],\n",
       "       [17.07826277],\n",
       "       [17.1115867 ],\n",
       "       [17.14491068],\n",
       "       [17.1782347 ],\n",
       "       [17.21155879],\n",
       "       [17.24488288],\n",
       "       [17.27820702],\n",
       "       [17.3115312 ],\n",
       "       [17.34485541],\n",
       "       [17.37817967],\n",
       "       [17.41150399],\n",
       "       [17.44482834],\n",
       "       [17.47815277],\n",
       "       [17.5114772 ],\n",
       "       [17.54480174],\n",
       "       [17.57812625],\n",
       "       [17.61145085],\n",
       "       [17.64477555],\n",
       "       [17.67810025],\n",
       "       [17.71142503],\n",
       "       [17.74474985],\n",
       "       [17.77807472],\n",
       "       [17.81139969],\n",
       "       [17.84472469],\n",
       "       [17.87804977],\n",
       "       [17.91137488],\n",
       "       [17.94470008],\n",
       "       [17.97802533],\n",
       "       [18.01135065],\n",
       "       [18.04467603],\n",
       "       [18.07800152],\n",
       "       [18.11132705],\n",
       "       [18.14465261],\n",
       "       [18.17797831],\n",
       "       [18.21130406],\n",
       "       [18.24462986],\n",
       "       [18.27795576],\n",
       "       [18.31128174],\n",
       "       [18.34460775],\n",
       "       [18.37793388],\n",
       "       [18.41126006],\n",
       "       [18.44458636],\n",
       "       [18.47791268],\n",
       "       [18.51123912],\n",
       "       [18.54456562],\n",
       "       [18.57789219],\n",
       "       [18.61121889],\n",
       "       [18.64454564],\n",
       "       [18.67787244],\n",
       "       [18.71119939],\n",
       "       [18.74452637],\n",
       "       [18.77785347],\n",
       "       [18.81118065],\n",
       "       [18.8445079 ],\n",
       "       [18.87783528],\n",
       "       [18.91116269],\n",
       "       [18.94449023],\n",
       "       [18.97781783],\n",
       "       [19.01114552],\n",
       "       [19.04447334],\n",
       "       [19.07780118],\n",
       "       [19.11112915],\n",
       "       [19.14445723],\n",
       "       [19.17778537],\n",
       "       [19.21111363],\n",
       "       [19.24444196],\n",
       "       [19.27777038],\n",
       "       [19.3110989 ],\n",
       "       [19.34442752],\n",
       "       [19.37775623],\n",
       "       [19.41108503],\n",
       "       [19.44441392],\n",
       "       [19.47774293],\n",
       "       [19.51107201],\n",
       "       [19.54440119],\n",
       "       [19.57773043],\n",
       "       [19.61105983],\n",
       "       [19.64438927],\n",
       "       [19.6777188 ],\n",
       "       [19.71104849],\n",
       "       [19.74437823],\n",
       "       [19.77770806],\n",
       "       [19.81103801],\n",
       "       [19.84436801],\n",
       "       [19.87769814],\n",
       "       [19.91102838],\n",
       "       [19.94435868],\n",
       "       [19.97768912],\n",
       "       [20.01101962],\n",
       "       [20.04435023],\n",
       "       [20.0776809 ],\n",
       "       [20.11101166],\n",
       "       [20.14434258],\n",
       "       [20.17767355],\n",
       "       [20.21100462],\n",
       "       [20.24433576],\n",
       "       [20.27766701],\n",
       "       [20.31099831],\n",
       "       [20.34432978],\n",
       "       [20.3776613 ],\n",
       "       [20.41099289],\n",
       "       [20.44432463],\n",
       "       [20.47765639],\n",
       "       [20.5109883 ],\n",
       "       [20.54432028],\n",
       "       [20.5776524 ],\n",
       "       [20.61098451],\n",
       "       [20.64431677],\n",
       "       [20.67764912],\n",
       "       [20.71098151],\n",
       "       [20.74431402],\n",
       "       [20.77764661],\n",
       "       [20.81097931],\n",
       "       [20.84431208],\n",
       "       [20.87764498],\n",
       "       [20.91097789],\n",
       "       [20.94431087],\n",
       "       [20.97764404],\n",
       "       [21.0109772 ],\n",
       "       [21.04431047],\n",
       "       [21.07764382],\n",
       "       [21.11097724],\n",
       "       [21.14431075],\n",
       "       [21.17764436],\n",
       "       [21.21097803],\n",
       "       [21.24431177],\n",
       "       [21.27764563],\n",
       "       [21.31097949],\n",
       "       [21.34431349],\n",
       "       [21.37764756],\n",
       "       [21.41098168],\n",
       "       [21.44431588],\n",
       "       [21.47765014],\n",
       "       [21.5109845 ],\n",
       "       [21.54431894],\n",
       "       [21.5776534 ],\n",
       "       [21.61098797],\n",
       "       [21.6443226 ],\n",
       "       [21.67765728],\n",
       "       [21.71099206],\n",
       "       [21.74432686],\n",
       "       [21.77766175],\n",
       "       [21.8109967 ],\n",
       "       [21.84433172],\n",
       "       [21.87766681],\n",
       "       [21.91100196],\n",
       "       [21.94433715],\n",
       "       [21.97767242],\n",
       "       [22.01100772],\n",
       "       [22.04434313],\n",
       "       [22.07767857],\n",
       "       [22.11101405],\n",
       "       [22.14434958],\n",
       "       [22.17768517],\n",
       "       [22.21102084],\n",
       "       [22.24435653],\n",
       "       [22.27769228],\n",
       "       [22.31102806],\n",
       "       [22.34436394],\n",
       "       [22.37769983],\n",
       "       [22.4110358 ],\n",
       "       [22.44437178],\n",
       "       [22.47770782],\n",
       "       [22.51104394],\n",
       "       [22.54438004],\n",
       "       [22.57771623],\n",
       "       [22.61105246],\n",
       "       [22.64438868],\n",
       "       [22.67772498],\n",
       "       [22.71106135],\n",
       "       [22.74439767],\n",
       "       [22.77773411],\n",
       "       [22.81107056],\n",
       "       [22.84440704],\n",
       "       [22.87774356],\n",
       "       [22.9110801 ],\n",
       "       [22.94441667],\n",
       "       [22.97775329],\n",
       "       [23.01108992],\n",
       "       [23.04442657],\n",
       "       [23.07776329],\n",
       "       [23.1111    ],\n",
       "       [23.14443676],\n",
       "       [23.17777352],\n",
       "       [23.21111033],\n",
       "       [23.24444714],\n",
       "       [23.27778396],\n",
       "       [23.31112086],\n",
       "       [23.34445774],\n",
       "       [23.37779466],\n",
       "       [23.41113158],\n",
       "       [23.44446848],\n",
       "       [23.47780549],\n",
       "       [23.51114246],\n",
       "       [23.54447943],\n",
       "       [23.57781645],\n",
       "       [23.61115349],\n",
       "       [23.64449052],\n",
       "       [23.67782754],\n",
       "       [23.71116465],\n",
       "       [23.74450171],\n",
       "       [23.77783879],\n",
       "       [23.81117587],\n",
       "       [23.84451297],\n",
       "       [23.87785007],\n",
       "       [23.91118717],\n",
       "       [23.94452434],\n",
       "       [23.97786147],\n",
       "       [24.01119861],\n",
       "       [24.04453572],\n",
       "       [24.07787288],\n",
       "       [24.11121002],\n",
       "       [24.14454715],\n",
       "       [24.17788431],\n",
       "       [24.21122146],\n",
       "       [24.24455864],\n",
       "       [24.27789576],\n",
       "       [24.31123292],\n",
       "       [24.34457008],\n",
       "       [24.37790724],\n",
       "       [24.41124437],\n",
       "       [24.44458151],\n",
       "       [24.47791867],\n",
       "       [24.5112558 ],\n",
       "       [24.54459295],\n",
       "       [24.57793007],\n",
       "       [24.61126718],\n",
       "       [24.6446043 ],\n",
       "       [24.67794142],\n",
       "       [24.7112785 ],\n",
       "       [24.74461561],\n",
       "       [24.77795268],\n",
       "       [24.81128977],\n",
       "       [24.84462685],\n",
       "       [24.87796392],\n",
       "       [24.91130097],\n",
       "       [24.94463802],\n",
       "       [24.97797505],\n",
       "       [25.01131208],\n",
       "       [25.04464909],\n",
       "       [25.07798608],\n",
       "       [25.11132309],\n",
       "       [25.14466002],\n",
       "       [25.177997  ],\n",
       "       [25.21133401],\n",
       "       [25.24467095],\n",
       "       [25.27800794],\n",
       "       [25.31134481],\n",
       "       [25.34468173],\n",
       "       [25.37801863],\n",
       "       [25.4113555 ],\n",
       "       [25.4446924 ],\n",
       "       [25.47802925],\n",
       "       [25.51136612],\n",
       "       [25.54470297],\n",
       "       [25.57803978],\n",
       "       [25.61137661],\n",
       "       [25.64471341],\n",
       "       [25.67805022],\n",
       "       [25.71138698],\n",
       "       [25.74472374],\n",
       "       [25.77806051],\n",
       "       [25.81139724],\n",
       "       [25.84473397],\n",
       "       [25.87807067],\n",
       "       [25.91140737],\n",
       "       [25.94474407],\n",
       "       [25.97808077],\n",
       "       [26.01141744],\n",
       "       [26.04475407],\n",
       "       [26.07809073],\n",
       "       [26.11142734],\n",
       "       [26.14476397],\n",
       "       [26.1781006 ],\n",
       "       [26.21143719],\n",
       "       [26.24477376],\n",
       "       [26.27811035],\n",
       "       [26.31144691],\n",
       "       [26.3447835 ],\n",
       "       [26.37812001],\n",
       "       [26.41145653],\n",
       "       [26.44479308],\n",
       "       [26.47812962],\n",
       "       [26.51146611],\n",
       "       [26.54480257],\n",
       "       [26.57813912],\n",
       "       [26.61147556],\n",
       "       [26.64481206],\n",
       "       [26.67814849],\n",
       "       [26.71148498],\n",
       "       [26.74482146],\n",
       "       [26.77815792],\n",
       "       [26.81149435],\n",
       "       [26.84483079],\n",
       "       [26.87816724],\n",
       "       [26.91150367],\n",
       "       [26.9448401 ],\n",
       "       [26.97817649],\n",
       "       [27.01151293],\n",
       "       [27.04484937],\n",
       "       [27.07818577],\n",
       "       [27.11152218],\n",
       "       [27.14485858],\n",
       "       [27.17819498],\n",
       "       [27.21153141],\n",
       "       [27.24486783],\n",
       "       [27.27820423],\n",
       "       [27.31154064],\n",
       "       [27.34487706],\n",
       "       [27.37821349],\n",
       "       [27.4115499 ],\n",
       "       [27.4448863 ],\n",
       "       [27.47822274],\n",
       "       [27.51155917],\n",
       "       [27.54489561],\n",
       "       [27.57823207],\n",
       "       [27.6115685 ],\n",
       "       [27.64490494],\n",
       "       [27.67824139],\n",
       "       [27.71157785],\n",
       "       [27.74491431],\n",
       "       [27.77825082],\n",
       "       [27.81158729],\n",
       "       [27.84492377],\n",
       "       [27.8782603 ],\n",
       "       [27.91159677],\n",
       "       [27.94493334],\n",
       "       [27.97826982],\n",
       "       [28.01160639],\n",
       "       [28.04494291],\n",
       "       [28.07827949],\n",
       "       [28.11161607],\n",
       "       [28.14495269],\n",
       "       [28.17828929],\n",
       "       [28.21162598],\n",
       "       [28.24496258],\n",
       "       [28.27829923],\n",
       "       [28.31163594],\n",
       "       [28.3449726 ],\n",
       "       [28.37830933],\n",
       "       [28.41164606],\n",
       "       [28.44498278],\n",
       "       [28.47831958],\n",
       "       [28.51165633],\n",
       "       [28.54499316],\n",
       "       [28.57832995],\n",
       "       [28.61166681],\n",
       "       [28.64500367],\n",
       "       [28.67834053],\n",
       "       [28.71167745],\n",
       "       [28.7450144 ],\n",
       "       [28.77835133],\n",
       "       [28.81168831],\n",
       "       [28.84502528],\n",
       "       [28.87836231],\n",
       "       [28.91169934],\n",
       "       [28.94503642],\n",
       "       [28.97837353],\n",
       "       [29.01171063],\n",
       "       [29.04504776],\n",
       "       [29.07838494],\n",
       "       [29.11172214],\n",
       "       [29.14505936],\n",
       "       [29.17839662],\n",
       "       [29.21173389],\n",
       "       [29.24507119],\n",
       "       [29.27840852]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_input to have 3 dimensions, but got array with shape (1, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-cc27c948ad34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m721\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kotta\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kotta\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kotta\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kotta\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[1;32m--> 646\u001b[1;33m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[0;32m    647\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kotta\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32mc:\\users\\kotta\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kotta\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    571\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    574\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected lstm_input to have 3 dimensions, but got array with shape (1, 1)"
     ]
    }
   ],
   "source": [
    "# pred = []\n",
    "# for i in range(0,721):\n",
    "#     predicted = regressor.predict(X_test[i])\n",
    "#     pred.append(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[5.31174912]]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 5.31174912\n",
    "np.reshape(x, (-1, 1, 1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_input to have 3 dimensions, but got array with shape ()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-4c4633027747>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\kotta\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kotta\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kotta\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kotta\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kotta\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, shuffle, standardize_function, **kwargs)\u001b[0m\n\u001b[0;32m    655\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstandardize_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m       x, y, sample_weights = standardize_function(\n\u001b[1;32m--> 657\u001b[1;33m           x=x, y=y, sample_weight=sample_weights)\n\u001b[0m\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m     self._internal_adapter = TensorLikeDataAdapter(\n",
      "\u001b[1;32mc:\\users\\kotta\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32mc:\\users\\kotta\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kotta\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    571\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    574\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected lstm_input to have 3 dimensions, but got array with shape ()"
     ]
    }
   ],
   "source": [
    "predicted = regressor.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
